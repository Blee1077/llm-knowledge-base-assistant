{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import pickle\n",
    "import gradio as gr\n",
    "from haystack.nodes import EmbeddingRetriever, PromptNode, PromptModel, PromptTemplate, AnswerParser\n",
    "from haystack.pipelines import Pipeline\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "BUCKET = 'knowledge-base-assist-demo'\n",
    "OPEN_AI_API_S3_KEY = 'openai_api_key.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(bucket: str, key: str) -> dict:\n",
    "    \"\"\"Loads a JSON file from S3 bucket.\n",
    "    \n",
    "    Args:\n",
    "        bucket (str): S3 bucket containing JSON file\n",
    "        key (str): Path within bucket of JSON file\n",
    "        \n",
    "    Returns:\n",
    "        dict\n",
    "    \"\"\"\n",
    "    content_object = s3.Object(bucket, key)\n",
    "    file_content = content_object.get()[\"Body\"].read().decode(\"utf-8\")\n",
    "    return json.loads(file_content)\n",
    "\n",
    "\n",
    "def create_initial_pipe(prompt_model: PromptModel, initial_template: str) -> Pipeline:\n",
    "    \"\"\"Create the initial pipeline for query classification.\n",
    "\n",
    "    Args:\n",
    "        prompt_model (PromptModel): The prompt model to be used in the PromptNode.\n",
    "        initial_template (str): The template for the initial prompt.\n",
    "\n",
    "    Returns:\n",
    "        Pipeline: The initial pipeline with a single PromptNode.\n",
    "    \"\"\"\n",
    "    initial_node = PromptNode(prompt_model, default_prompt_template=initial_template)\n",
    "    initial_pipe = Pipeline()\n",
    "    initial_pipe.add_node(component=initial_node, name=\"initial_prompt_node\", inputs=[\"Query\"])\n",
    "    \n",
    "    return initial_pipe\n",
    "\n",
    "\n",
    "def create_lfqa_section_doc_pipe(prompt_model: PromptModel, split_doc_retriever: EmbeddingRetriever) -> Pipeline:\n",
    "    \"\"\"Create the LFQA pipeline for answering questions using document sections.\n",
    "\n",
    "    Args:\n",
    "        prompt_model (PromptModel): The prompt model to be used in the PromptNode.\n",
    "        split_doc_retriever (EmbeddingRetriever): The retriever for obtaining document sections.\n",
    "\n",
    "    Returns:\n",
    "        Pipeline: The LFQA pipeline with a Split Document Retriever and a PromptNode.\n",
    "    \"\"\"\n",
    "    lfqa_section_node = PromptNode(prompt_model, default_prompt_template=\"question-answering\")\n",
    "    lfqa_section_pipe = Pipeline()\n",
    "    lfqa_section_pipe.add_node(component=split_doc_retriever, name=\"split_doc_retriever\", inputs=[\"Query\"])\n",
    "    lfqa_section_pipe.add_node(component=lfqa_section_node, name=\"lfqa_prompt_node\", inputs=[\"split_doc_retriever\"])\n",
    "    \n",
    "    return lfqa_section_pipe\n",
    "\n",
    "\n",
    "def create_lfqa_whole_doc_pipe(prompt_model: PromptModel, whole_doc_retriever: EmbeddingRetriever) -> Pipeline:\n",
    "    \"\"\"Create the LFQA pipeline for answering questions using whole documents.\n",
    "\n",
    "    Args:\n",
    "        prompt_model (PromptModel): The prompt model to be used in the PromptNode.\n",
    "        whole_doc_retriever (EmbeddingRetriever): The retriever for obtaining whole documents.\n",
    "\n",
    "    Returns:\n",
    "        Pipeline: The LFQA pipeline with a Whole Document Retriever and a PromptNode.\n",
    "    \"\"\"\n",
    "    lfqa_whole_node = PromptNode(prompt_model, default_prompt_template=\"question-answering\")\n",
    "    lfqa_whole_pipe = Pipeline()\n",
    "    lfqa_whole_pipe.add_node(component=whole_doc_retriever, name=\"whole_doc_retriever\", inputs=[\"Query\"])\n",
    "    lfqa_whole_pipe.add_node(component=lfqa_whole_node, name=\"summariser_prompt_node\", inputs=[\"whole_doc_retriever\"])\n",
    "    \n",
    "    return lfqa_whole_pipe\n",
    "\n",
    "\n",
    "def extract_outputs(output: Dict) -> Tuple[str, Dict[str, str]]:\n",
    "    \"\"\"Extract the answer and documents from the pipeline output.\n",
    "\n",
    "    Args:\n",
    "        output (dict): The output dictionary from the pipeline.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the answer (str) and a dictionary of documents.\n",
    "    \"\"\"\n",
    "    answer = output['answers'][0].answer\n",
    "    docs = {f\"Document {idx}\": {'content': doc.content, 'name': doc.meta['name']} for idx, doc in enumerate(output['documents'], start=1)}\n",
    "    return answer, docs\n",
    "\n",
    "\n",
    "def process_query(query: str, pipeline: Pipeline) -> Tuple[str, Dict[str, str]]:\n",
    "    \"\"\"Processes a user's query using the specified pipeline and extracts the answer and related documents.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user's query.\n",
    "        pipeline (Pipeline): The Haystack pipeline used to process the query and generate an answer.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the answer (str) and a dictionary of related documents.\n",
    "    \"\"\"\n",
    "    answer_output = pipeline.run(query=query)\n",
    "    return extract_outputs(answer_output)\n",
    "\n",
    "\n",
    "def run_lfqa(query: str, initial_pipe: Pipeline, lfqa_section_pipe: Pipeline, lfqa_whole_pipe: Pipeline) -> Tuple[str, Dict[str, str]]:\n",
    "    \"\"\"Runs the initial pipeline to classify the query, then runs the appropriate LFQA\n",
    "    pipeline based on the query classification result.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user's query.\n",
    "        initial_pipe (Pipeline): The initial pipeline for query classification.\n",
    "        lfqa_section_pipe (Pipeline): The LFQA pipeline for answering questions using document sections.\n",
    "        lfqa_whole_pipe (Pipeline): The LFQA pipeline for answering questions using whole documents.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the answer (str) and a dictionary of documents.\n",
    "    \"\"\"\n",
    "    initial_output = initial_pipe.run(query=query)\n",
    "    query_class = initial_output['answers'][0].answer\n",
    "    \n",
    "    if 'section' in query_class.lower():\n",
    "        return process_query(query, lfqa_section_pipe)\n",
    "    elif 'whole' in query_class.lower():\n",
    "        return process_query(query, lfqa_whole_pipe)\n",
    "    else:\n",
    "        return \"Answer cannot be provided with internal knowledge base.\", {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('whole_doc_store.pkl', 'rb') as f:\n",
    "    whole_doc_store = pickle.load(f)\n",
    "\n",
    "with open('split_doc_store.pkl', 'rb') as f:\n",
    "    split_doc_store = pickle.load(f)\n",
    "\n",
    "openai_secrets = load_json(bucket=BUCKET, key=OPEN_AI_API_S3_KEY)\n",
    "OPENAI_API_KEY = openai_secrets['Key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_names = [\n",
    "        \"Attendance and remote work policy: Guidelines for employee attendance, remote work eligibility, home office allowances, and communication expectations at Dunder Mifflin.\",\n",
    "        \"Benefits and compensation policy: Outlines payroll procedures, medical benefits, wellness programs, bonuses, allowances, retirement plans, and other benefits to support employee well-being and work-life balance.\",\n",
    "        \"Code of conduct policy: Outlines standards of behavior, emphasizing core values of the company. Employees must adhere to ethical conduct, professionalism, diversity, conflict of interest, confidentiality, health and safety, and anti-harassment policies.\",\n",
    "        \"Expense policy: Covers reimbursement for authorized business expenses, such as travel, accommodation, meals, and conferences. Employees must obtain prior approval, submit expense reports with documentation, and adhere to guidelines for corporate credit card usage.\",\n",
    "        \"Health and safety policy: Outlines shared responsibilities among employees to maintain a safe workplace. Includes hazard identification, risk assessment, accident reporting, emergency procedures, and training.\",\n",
    "        \"Employee leave policy: Covers vacation, sick leave, public holidays, parental, bereavement, jury duty, unpaid leave, work from home, leave donation, professional development, and military leave.\",\n",
    "        \"Performance evaluation and promotion policy: outlines annual evaluations, promotion processes, and criteria. The policy emphasizes fairness, transparency, employee growth.\",\n",
    "        \"Recruitment policy: outlines principles and processes for attracting, selecting, and onboarding employees. The policy covers candidate selection criteria, recruitment process, employee referral program, and comprehensive onboarding.\",\n",
    "        \"Employee termination policy: Outlines guidelines for voluntary and involuntary terminations, ensuring fairness and legal compliance. It covers resignation notice, performance-based termination, layoffs, termination for cause, notice periods, exit interviews, final pay, benefits continuation, and return of company property.\",\n",
    "        \"Employee working hours policy: Outlines guidelines for standard working hours, flexible schedules, breaks, and overtime, promoting a healthy work-life balance and legal compliance. Covers timekeeping, overtime compensation, approval, recordkeeping.\",\n",
    "        \"IT acceptable use policy: Outlines employee responsibilities for using company technology resources securely and efficiently, including authorization, personal use, security measures, password protection, email etiquette, data communication, software installation, remote access, and file storage.\"\n",
    "    ]\n",
    "\n",
    "initial_template = PromptTemplate(\n",
    "                name=\"initial-prompt\",\n",
    "                prompt_text=f\"You are a knowledge base assistant for Dunder Mifflin Paper Company, Inc. and you have access to the following HR and IT policies: {' ,'.join(policy_names)}\"\n",
    "                \"Your task is to Determine if user query needs entire an policy (answer 'Whole'), a section (answer 'Section'), or cannot be answered using policies (answer 'N/A').\"\n",
    "                \"Only use 'Whole', 'Section', or 'N/A' as response with no additional text.\"\n",
    "                \"User query: {query}; Answer:\",\n",
    "                output_parser=AnswerParser(),\n",
    "            )\n",
    "\n",
    "prompt_model = PromptModel(model_name_or_path=\"gpt-3.5-turbo\", max_length=750, api_key=OPENAI_API_KEY)\n",
    "\n",
    "# OpenAI EmbeddingRetriever\n",
    "split_doc_retriever = EmbeddingRetriever(\n",
    "    document_store=split_doc_store,\n",
    "    batch_size=8,\n",
    "    use_gpu=False,\n",
    "    embedding_model=\"text-embedding-ada-002\",\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    max_seq_len=8192,\n",
    "    top_k=3\n",
    ")\n",
    "\n",
    "whole_doc_retriever = EmbeddingRetriever(\n",
    "    document_store=whole_doc_store,\n",
    "    batch_size=8,\n",
    "    use_gpu=False,\n",
    "    embedding_model=\"text-embedding-ada-002\",\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    max_seq_len=8192,\n",
    "    top_k=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_pipe = create_initial_pipe(prompt_model, initial_template)\n",
    "lfqa_section_pipe = create_lfqa_section_doc_pipe(prompt_model, split_doc_retriever)\n",
    "lfqa_whole_pipe = create_lfqa_whole_doc_pipe(prompt_model, whole_doc_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca395c69c296431dbf46c183f49e4b29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d2405c3aa0409b9bd286c6d5812609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def gradio_interface(query: str) -> Tuple[str, Dict[str, str]]:\n",
    "    max_retries = 3\n",
    "    retries = 0\n",
    "\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            answer, docs = run_lfqa(query, initial_pipe, lfqa_section_pipe, lfqa_whole_pipe)\n",
    "            formatted_docs = \"\\n\\n\".join([f\"{key} ({value['name']}):\\n{value['content']}\" for key, value in docs.items()])\n",
    "            return answer, formatted_docs\n",
    "        \n",
    "        except Exception as e:\n",
    "            if 'timed out' in str(e):\n",
    "                retries += 1\n",
    "                if retries == max_retries:\n",
    "                    raise Exception(\n",
    "                        \"Error: The server took too long to respond. Please try again later.\",\n",
    "                    )\n",
    "            else:\n",
    "                raise Exception(\"Unexpected error occured.\")\n",
    "\n",
    "# Define example inputs\n",
    "EXAMPLES = [\n",
    "    \"What is the remote work policy?\",\n",
    "    \"How are performance evaluations conducted?\",\n",
    "    \"What is the process for employee recruitment?\",\n",
    "    \"What are the guidelines for employee working hours?\",\n",
    "    \"How do employees report business expenses for reimbursement?\",\n",
    "    \"What is the code of conduct policy?\",\n",
    "    \"What types of employee leaves are available?\",\n",
    "    \"How does the company handle employee termination?\",\n",
    "]\n",
    "\n",
    "APP_DESCRIPTION = \"\"\"\n",
    "Welcome to the Dunder Mifflin Paper Company, Inc. Knowledge Base Assistant. \n",
    "This tool is powered by advanced AI models and is designed to answer questions related to the company's Human Resource and IT policies.\n",
    "\n",
    "Simply enter your question in the textbox and the Assistant will provide a synthesized answer along with any relevant documents from the knowledge base. \n",
    "\n",
    "The Assistant's responses are based on the following documents in our database:\n",
    "1. Attendance and remote work policy - Guidelines for employee attendance, remote work eligibility, home office allowances, and communication expectations.\n",
    "2. Benefits and compensation policy - Outlines payroll procedures, medical benefits, wellness programs, bonuses, allowances, retirement plans, and other benefits to support employee well-being and work-life balance.\n",
    "3. Code of conduct policy - Standards of behavior emphasizing the company's core values. Details ethical conduct, professionalism, diversity, conflict of interest, confidentiality, health and safety, and anti-harassment policies.\n",
    "4. Expense policy - Covers authorized business expense reimbursements such as travel, accommodation, meals, and conferences. Outlines the process for obtaining prior approval, submitting expense reports with documentation, and corporate credit card usage guidelines.\n",
    "5. Health and safety policy - Shared responsibilities among employees to maintain a safe workplace. Includes hazard identification, risk assessment, accident reporting, emergency procedures, and training.\n",
    "6. Employee leave policy - Covers various types of leave including vacation, sick leave, public holidays, parental, bereavement, jury duty, unpaid leave, work from home, leave donation, professional development, and military leave.\n",
    "7. Performance evaluation and promotion policy - Annual evaluations, promotion processes, and criteria. Emphasizes fairness, transparency, and employee growth.\n",
    "8. Recruitment policy - Principles and processes for attracting, selecting, and onboarding employees. Covers candidate selection criteria, recruitment process, employee referral program, and comprehensive onboarding.\n",
    "9. Employee termination policy - Guidelines for voluntary and involuntary terminations. Covers resignation notice, performance-based termination, layoffs, termination for cause, notice periods, exit interviews, final pay, benefits continuation, and return of company property.\n",
    "10. Employee working hours policy - Standard working hours, flexible schedules, breaks, and overtime. Promotes a healthy work-life balance and legal compliance. Covers timekeeping, overtime compensation, approval, recordkeeping.\n",
    "11. IT acceptable use policy - Employee responsibilities for using company technology resources securely and efficiently. Includes authorization, personal use, security measures, password protection, email etiquette, data communication, software installation, remote access, and file storage.\n",
    "\n",
    "Please note that the Assistant will classify your question and determine whether the answer lies in a whole document, a document's section, or if it cannot be answered using the available policies. If you have any questions not related to these documents, the Assistant may not be able to provide a precise answer.\n",
    "\"\"\"\n",
    "\n",
    "# Create Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=gradio_interface,\n",
    "    inputs=gr.inputs.Textbox(lines=2, label=\"Enter your query\"),\n",
    "    outputs=[\n",
    "        gr.outputs.Textbox(label=\"Answer\"),\n",
    "        gr.outputs.Textbox(label=\"Relevant Documents\")\n",
    "    ],\n",
    "    examples=EXAMPLES,\n",
    "    cache_examples=False,\n",
    "    allow_flagging='never',\n",
    "    title=\"Dunder Mifflin Knowledge Base Assistant using ChatGPT\",\n",
    "    description=APP_DESCRIPTION,\n",
    ")\n",
    "\n",
    "# Launch Gradio interface\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_assist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
